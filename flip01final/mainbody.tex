%=================================================================
\section{Introduction}\label{sec-intro}


%Test citation~\cite{BL12J01}. 
%\begin{JournalOnly}
%and~\citep{BJL11J01} or~\citet{BJL11J01}.
%\end{JournalOnly}

%This is for~\cref{tbl:overall-experiments}, 
%\todo[fancyline]{Testing.}
%and this is for~\cref{sec-conclusions}.
%\todo[noline]{A note with no line back to the text.}%
%\gangli{This is comment from Gang.}
%\qwu{Response from QW}

%Number:
%\num{123}.
%\numlist{10;30;50;70},
%\numrange{10}{30},
%\SIlist{10;30;45}{\metre},
%and
%\SI{10}{\percent}

%\missingfigure[figcolor=white]{Testing figcolor}
\subsection{Problem Statement}
\

Using 8 years daily news headlines to predict stock market movement
\subsection{Data List}
\
The Kaggle dataset contains date, label, and 28 columns of same-day news data.
The data were divided into a training set and a test set to 
predict the relationship between news information and 
stock market movements on the day.
\begin{description}
  \item [date] - Date information.
  \item [label] - 1 for trading, 0 for falling.
  \item [top x] - News ID.
\end{description}

%\subsection{Problem Analysis}
%\

%This problem is a text multi-classification problem in a typical natural language processing problem.
%First, the text data is cleaned. Second, the words in the text are converted into word vectors, 
%which can then be processed by the computer. Finally put it into the classification model for classification.

\section{Exploratory Data Analysis} \label{sec-data_exploration}

\subsection{Data Information}
\

In the table, there are date, label and 25 column top values, 
respectively representing the date, 
whether the stock market rose or fell and 
the news information of the day.
Through the training of the data, 
in order to get the relationship between 
the rise and fall of the stock market and the news of the day.

\begin{table}[htbp]  \centering
	\caption{The head of the train data}
	\label{tbl:data information}
	\begin{tabular}{ccccccc}
		\hline
		% after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    & Date & label & Top1 & ...\\
    \hline
    0 & 2016-08-08    & 0     & b"Georgia 'downs two Russian warplanes' as cou... & ...\\
    1 & 2016-08-11    & 1     & b'Why wont America and Nato help us? If they w... & ...\\
    2 & 2016-08-12    & 0     & b'Remember that adorable 9-year-old who sang a... & ...\\
    3 & 2016-08-13    & 0     & b' U.S. refuses Israel weapons to attack Iran:... & ...\\
    4 & 2016-08-14    & 1     & b'All the experts admit that we should legalis... & ...\\
    5 & ...           & ...   & ...                                               & ...\\
        \hline 
		%\bottomrule
	\end{tabular}
\end{table}

%\begin{table}[htbp]  \centering
%    \caption{The head of the test data}
%    \label{tbl:data information}
%    \begin{tabular}{ccccccc}
%      % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
%      & id & ingredients\\
%      \hline
%      0  & 18009 & [baking powder, eggs, all-purpose flour, raisi... \\
%      1  & 28583 & [sugar, egg yolks, corn starch, cream of tarta... \\
%      2  & 41580 & [sausage links, fennel bulb, fronds, olive oil... \\
%      3  & 29752 & [meat cuts, file powder, smoked sausage, okra,... \\
%      4  & 35687 & [ground black pepper, salt, sausage casings, l... \\
%      \hline 
      %\bottomrule
%    \end{tabular}
%  \end{table}

\subsection{Text Processing}
\

Text data is data information that cannot be recognized by a computer. 
Only by digitizing text data can a computer be able to process the data.
This chapter mainly introduces the processing method of text data.

\begin{itemize}
	\item Get rid of the HTML tag
  \item Remove the punctuation
  \item Cut into the word /token
  \item stopwords
  \item Reorganize into new sentences
  \end{itemize}
\subsubsection{Get rid of the HTML tag}
\
Get rid of the HTML tag is the first step 
in data processing to prevent information other than the data 
from interfering with the data.


\subsubsection{Remove the punctuation}
\

To Remove the punctuation is to eliminate 
the interference of punctuation marks. In text messages, 
it is not necessary to recognize symbol information.
\subsubsection{stopwords}
\
In text data, there are many words that are necessary, 
but computer processing is not.
 For these words, t
 hey can be removed to mention the efficiency of computer recognition

%\subsection{visualization}
%\ 

%Draw word cloud for text by using word cloud technology. In this way, we can know which words 
%appear more frequently in the text, which may provide some reference for our future model selection and model processing.

%\begin{figure}[ht]%插入图片
%	\centering%用于居中
%	\includegraphics[scale=1]{E:/tulip-flip/flip01/photo/01.eps}
%	\caption{Displaying the words in text}%图片标题
%\end{figure} 

%\begin{figure}[ht]%插入图片
%	\centering%用于居中
%	\includegraphics[scale=0.9]{E:/tulip-flip/flip01/photo/05.eps}
%	\caption{Displaying the words in text}%图片标题
%\end{figure}
%\vspace{2cm}
%From Figure 1 and Figure 2, we can see that Mexican is the most frequently occurring in Cuisine.
%And salt onions and other words are the most frequent words in the recipe.

\section{Models}

After processing natural language, 
it is necessary to train it. 
There are many training methods.
 In this paper, SVM,CNN and LSTM are mainly used for training.
\begin{itemize}
	\item  LSTM
	\item  SVM
	\item  CNN
  \end{itemize}
\subsection{word2vec}
\ 

Word2vector is a way to convert language text into a number vector.
It contains the following steps:
\begin{itemize}
	\item  Word segmentation/stem extraction and morphological reduction
	\item  Use the following five models to classify the preprocessed data
	\item  Construct a tree structure
	\item Generates the binary code of the node
	\item Initializes the intermediate vector of each non-leaf node and the word vector in the leaf node
	\item Train the intermediate vector and the word vector
  \end{itemize}



\subsection{ model}
\

Use the following five models to classify the preprocessed data

\subsubsection{LSTM}
\

Train on 1611 samples, validate on 378 samples\\
Epoch 1/3\\
1611/1611 [==============================] - 50s - loss: 0.6942 - acc: 0.5208 - val_loss: 0.6935 - val_acc: 0.5079\\
Epoch 2/3\\
1611/1611 [==============================] - 51s - loss: 0.6722 - acc: 0.5971 - val_loss: 0.6904 - val_acc: 0.5106\\
Epoch 3/3\\
1611/1611 [==============================] - 50s - loss: 0.5941 - acc: 0.7492 - val_loss: 0.6831 - val_acc: 0.5661\\
378/378 [==============================] - 3s \\    
Test score: 0.683092702633\\
Test accuracy: 0.566137566138\\
prediction accuracy:  0.566137566138\\
 \

 
 \subsubsection{CNN}
 \

 Train on 1611 samples, validate on 378 samples\\
Epoch 1/1\\
1611/1611 [==============================] - 14s - loss: 0.6900 - acc: 0.5317 - val_loss: 0.6974 - val_acc: 0.5079\\
352/378 [==========================>...] - ETA: 0sTest score: 0.69742725829\\
Test accuracy: 0.507936509829\\
prediction accuracy:  0.507936507937\\
\
 
%\begin{figure}[ht]%插入图片
%	\centering%用于居中
%	\includegraphics[scale=1]{E:/tulip-flip/flip01/photo/03.eps}
%	\caption{Displaying the relationship between the loss and epoch}%图片标题
%\end{figure} 

%\begin{figure}[ht]%插入图片
%	\centering%用于居中
%	\includegraphics[scale=1]{E:/tulip-flip/flip01/photo/04.eps}
%	\caption{Displaying the relationship between the accuracy and epoch}%图片标题
%\end{figure}
% \

% It can be seen that the model gradually started to stabilize when iterating about 10 times.

 \subsubsection{model score}
 \

 The accuracy of each model is obtained through model training. Show in the table below.
 \
 
 \begin{table}[htbp]  \centering
    \caption{The score of models}
    \label{tbl:data information}
    \begin{tabular}{ccccccc}
      \hline
      % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
      & model          & score \\
      \hline
      1 &  LSTM          & 0.566137566138  \\
      2 &  CNN           & 0.507936507937  \\
      3 &  svm           & 0.595238095238  \\
      \hline 
      %\bottomrule
    \end{tabular}
  \end{table}
 %\begin{ConferenceOnly}
%We have \SI{10}{\hertz},
%\si{\kilogram\metre\per\second},
%the range: \SIrange{10}{100}{\hertz}.
%$\nicefrac[]{1}{2}$.

%\missingfigure{Make a sketch of the structure of a trebuchet.}

%\end{ConferenceOnly}


%For~\cref{eq:test},
%as shown below:

%\begin{equation}\label{eq:test}
%a = b \times \sqrt{ab}
%\end{equation}

%\blindmathpaper

\section{Experiment and Analysis}
\

  [1] At present, we can only simply use the function call of the algorithm in NLP, and the parameter setting inside the function is still in the initial stage
 

\section{Conclusion}
[1] I need to master a variety of natural language processing methods\\
[2] The next step is to improve the quality of the algorithm based on the internal principles of the function\\
%\section{Preliminaries} \label{sec-preliminaries}

%\blindtext

%\gliMarker  %TODO: GLi Here


%\section{Method} \label{sec-method}

%\blindtext
%\blindlist{itemize}[3]
%\blinditemize
%\blindenumerate

%\blindmathtrue
%\blindmathfalse
%\blinddescription

%\qwuMarker %TODO: QWu Here

%\section{Experiment and Analysis} \label{sec-experiment}


%\begin{table}  \centering
  %\caption{Precision Comparison on Event Detection Methods}
  %\label{tbl:overall-experiments}
  %\begin{tabular}{cccc}
%\toprule
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    %& OR Event Detection & AC Event Detection & TC Event Detection \\
%\midrule
    %precision & 0.83 & 0.69 & 0.46 \\
    %recall & 0.68 & 0.48 & 0.36 \\
    %F-score & 0.747 & 0.57 & 0.4 \\
%\bottomrule
%\end{tabular}
%\end{table}


%\section{Conclusions} \label{sec-conclusions}

%\blindtext

%\section*{Acknowledgment}

%\lipsum[1]


%The authors would like to thank \ldots

